{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprob\n",
    "from pyprob import Model\n",
    "import numpy as np\n",
    "from pyprob.distributions import Normal, Uniform\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vac = 3E8\n",
    "\n",
    "def sph_to_cart(theta, phi=0, r=1):\n",
    "    \"\"\"Transform spherical to cartesian coordinates.\"\"\"\n",
    "    x = r * torch.sin(theta) * torch.cos(phi)\n",
    "    y = r * torch.sin(theta) * torch.sin(phi)\n",
    "    z = r * torch.cos(theta)\n",
    "\n",
    "    return torch.tensor([x, y, z], device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConditioningOnTailExample(Model):\n",
    "    def __init__(self, target_x, target_r):\n",
    "        super().__init__(name=\"ConditioningOnTailExample\")\n",
    "\n",
    "        self.target_x = target_x\n",
    "        self.target_r = target_r\n",
    "\n",
    "\n",
    "\n",
    "    def photon_sphere_intersection(self, \n",
    "        photon_x, photon_p, step_size\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calculate intersection.\n",
    "\n",
    "        Given a photon origin, a photon direction, a step size, a target location and a target radius,\n",
    "        calculate whether the photon intersects the target and the intrsection point.\n",
    "\n",
    "        Parameters:\n",
    "            photon_x: float[3]\n",
    "            photon_p: float[3]\n",
    "            step_size: float\n",
    "\n",
    "        Returns:\n",
    "            tuple(bool, float[3])\n",
    "                True and intersection position if intersected.\n",
    "        \"\"\"\n",
    "        p_normed = photon_p  # assume normed\n",
    "\n",
    "        a = torch.dot(p_normed, (photon_x - self.target_x))\n",
    "        b = a**2 - (torch.linalg.norm(photon_x - target_x) ** 2 - self.target_r**2)\n",
    "        # Distance of of the intersection point along the line\n",
    "        d = -a - torch.sqrt(b)\n",
    "\n",
    "        isected = (b >= 0) & (d > 0) & (d < step_size)\n",
    "\n",
    "        if isected:\n",
    "            return True, photon_x + d * p_normed\n",
    "\n",
    "        else:\n",
    "            return False, torch.tensor([1E8, 1E8, 1E8], device=device)\n",
    "   \n",
    "    def scattering_func(self, g=0.97):\n",
    "        \"\"\"Henyey-Greenstein scattering in one plane.\"\"\"\n",
    "        eta = pyprob.sample(Uniform(0, 1), name=\"scattering_eta\")\n",
    "        costheta = (\n",
    "            1 / (2 * g) * (1 + g**2 - ((1 - g**2) / (1 + g * (2 * eta - 1))) ** 2)\n",
    "        )\n",
    "        return torch.arccos(costheta)\n",
    "\n",
    "    def initialize_direction_isotropic(self):\n",
    "        \"\"\"Draw direction uniformly on a sphere.\"\"\"\n",
    "        \n",
    "        theta = torch.arccos(pyprob.sample(Uniform(-1, 1), name=\"init_theta\"))\n",
    "        phi = pyprob.sample(Uniform(0, 2*np.pi), name=\"init_phi\")\n",
    "        direction = sph_to_cart(theta, phi, r=1)\n",
    "\n",
    "        return direction\n",
    "\n",
    "\n",
    "    def calc_new_direction(self, old_dir):\n",
    "        \"\"\"\n",
    "        Calculate new direction after sampling a scattering angle.\n",
    "\n",
    "        Scattering is calculated in a reference frame local\n",
    "        to the photon (e_z) and then rotated back to the global coordinate system.\n",
    "        \"\"\"\n",
    "\n",
    "        theta = self.scattering_func()\n",
    "\n",
    "        cos_theta = torch.cos(theta)\n",
    "        sin_theta = torch.sin(theta)\n",
    "\n",
    "        phi = pyprob.sample(Uniform(0, 2 * np.pi), name=\"scattering_phi\")\n",
    "        cos_phi = torch.cos(phi)\n",
    "        sin_phi = torch.sin(phi)\n",
    "\n",
    "        px, py, pz = old_dir\n",
    "\n",
    "        is_para_z = torch.abs(pz) == 1\n",
    "\n",
    "        if is_para_z:\n",
    "            new_dir = torch.tensor(\n",
    "                [\n",
    "                    sin_theta * cos_phi,\n",
    "                    torch.sign(pz) * sin_theta * sin_phi,\n",
    "                    torch.sign(pz) * cos_theta,\n",
    "                ],\n",
    "                device=device\n",
    "            )\n",
    "        else:\n",
    "            new_dir = torch.tensor(\n",
    "                 [\n",
    "                    (px * cos_theta)\n",
    "                    + (\n",
    "                        (sin_theta * (px * pz * cos_phi - py * sin_phi))\n",
    "                        / (torch.sqrt(1.0 - pz**2))\n",
    "                    ),\n",
    "                    (py * cos_theta)\n",
    "                    + (\n",
    "                        (sin_theta * (py * pz * cos_phi + px * sin_phi))\n",
    "                        / (torch.sqrt(1.0 - pz**2))\n",
    "                    ),\n",
    "                    (pz * cos_theta) - (sin_theta * cos_phi * torch.sqrt(1.0 - pz**2)),\n",
    "                ],\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "        # Need this for numerical stability?\n",
    "        new_dir = new_dir / torch.linalg.norm(new_dir)\n",
    "\n",
    "        return new_dir\n",
    "\n",
    "    def scattering_length_function(self, wavelength):\n",
    "        return 40.\n",
    "\n",
    "    def ref_index_func(self, wavelength):\n",
    "        return 1.32\n",
    "\n",
    "    def step(self, photon_state):\n",
    "        \"\"\"Single photon step.\"\"\"\n",
    "        pos = photon_state[\"pos\"]\n",
    "        dir = photon_state[\"dir\"]\n",
    "        time = photon_state[\"time\"]\n",
    "        isec = photon_state[\"intersected\"]\n",
    "        stepcnt = photon_state[\"steps\"]\n",
    "        wavelength = photon_state[\"wavelength\"]\n",
    "\n",
    "        sca_coeff = 1 / self.scattering_length_function(wavelength)\n",
    "        c_medium = (\n",
    "            c_vac * 1e-9 / self.ref_index_func(wavelength)\n",
    "        )  # m/ns\n",
    "\n",
    "        eta = pyprob.sample(Uniform(0, 1), name=\"step_len_eta\") # could just sample from expon\n",
    "        step_size = -torch.log(eta) / sca_coeff\n",
    "\n",
    "        dstep = step_size * dir\n",
    "        new_pos = pos + dstep\n",
    "        new_time = time + step_size / c_medium\n",
    "\n",
    "        # Calculate intersection\n",
    "        isec, isec_pos = self.photon_sphere_intersection(\n",
    "            photon_x=pos,\n",
    "            photon_p=dir,\n",
    "            step_size=step_size,\n",
    "        )\n",
    "\n",
    "        if isec:\n",
    "            new_pos = isec_pos\n",
    "            new_time =  time + torch.linalg.norm(pos - isec_pos) / c_medium\n",
    "            new_dir = dir\n",
    "        else:\n",
    "            new_dir = self.calc_new_direction(dir)\n",
    "            stepcnt += 1\n",
    "\n",
    "        new_photon_state = {\n",
    "            \"pos\": new_pos,\n",
    "            \"dir\": new_dir,\n",
    "            \"time\": new_time,\n",
    "            \"intersected\": isec,\n",
    "            \"steps\": stepcnt,\n",
    "            \"wavelength\": wavelength,\n",
    "        }\n",
    "\n",
    "        return new_photon_state\n",
    "\n",
    "    def loop(self, state):\n",
    "\n",
    "        while((state[\"steps\"] < 10) and not state[\"intersected\"]):\n",
    "            state = self.step(state)\n",
    "        return state\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        state = {\"dir\": self.initialize_direction_isotropic(),\n",
    "                 \"pos\": torch.tensor([0., 0., 0.], device=device),\n",
    "                 \"steps\": 0,\n",
    "                 \"time\": 0,\n",
    "                 \"intersected\": False,\n",
    "                 \"wavelength\": 450}\n",
    "\n",
    "        state = self.loop(state)\n",
    "\n",
    "        probs = [0,1] if state[\"intersected\"] else [1,0]\n",
    "\n",
    "        obs_distr = pyprob.distributions.Categorical(probs)\n",
    "\n",
    "        pyprob.observe(obs_distr, name='obs0')\n",
    "        return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = torch.tensor([0., 0., 10.], device=device)\n",
    "target_r = 0.5\n",
    "model = ConditioningOnTailExample(target_x, target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n",
      "Observable obs0: reshape not specified, using shape torch.Size([]).\n",
      "Observable obs0: using embedding dim torch.Size([64]).\n",
      "Observable obs0: observe embedding not specified, using the default FEEDFORWARD.\n",
      "Observable obs0: using embedding depth 3.\n",
      "Observe embedding dimension: 64\n",
      "Train. time | Epoch| Trace     | Init. loss| Min. loss | Curr. loss| T.since min | Learn.rate| Traces/sec\n",
      "New layers, address: 20__forward__initialize_direction_isotropic__?__Un..., distribution: Uniform\n",
      "New layers, address: 48__forward__initialize_direction_isotropic__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__1, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__2, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__3, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__4, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__5, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__6, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__7, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__8, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__9, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "New layers, address: 96__forward__loop__step__eta__Uniform__10, distribution: Uniform\n",
      "New layers, address: 16__forward__loop__step__calc_new_direction__scatt..., distribution: Uniform\n",
      "New layers, address: 50__forward__loop__step__calc_new_direction__phi__..., distribution: Uniform\n",
      "Total addresses: 32, distribution types: 1, parameters: 6,210,568\n",
      "0d:00:07:48 | 1    | 9,984     | +2.09e+01 | +2.06e+01 | \u001b[31m+2.09e+01\u001b[0m | 0d:00:03:26 | +1.00e-03 | 19.3                               \n",
      "Stop condition reached. num_traces: 10000\n",
      "0d:00:07:52 | 1    | 10,048    | +2.09e+01 | +2.06e+01 | \u001b[32m+2.09e+01\u001b[0m | 0d:00:03:30 | +1.00e-03 | 16.8                               \n"
     ]
    }
   ],
   "source": [
    "model.learn_inference_network(\n",
    "    num_traces=10000,\n",
    "    observe_embeddings={'obs0': {'dim': 64, 'depth': 3}},\n",
    "    inference_network=pyprob.InferenceNetwork.LSTM\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent  | Time remain.| Progress             | Trace     | ESS    | Traces/sec\n",
      "0d:00:01:21 | 0d:00:00:00 | #################### | 2000/2000 | 2000.00 | 24.67       \n",
      "Time spent  | Time remain.| Progress             | Trace     | ESS    | Traces/sec\n",
      "0d:00:14:23 | 0d:00:00:00 | #################### | 2000/2000 |   3.00 | 2.32        \n"
     ]
    }
   ],
   "source": [
    "condition  = {'obs0': 1}\n",
    "\n",
    "prior = model.prior(\n",
    "    num_traces=2000,\n",
    ")\n",
    "posterior = model.posterior(\n",
    "    num_traces=2000,\n",
    "    inference_engine=pyprob.InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK,\n",
    "    observe=condition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = [prior.sample() for x in range(1000)]\n",
    "post_samples  = [posterior.sample() for x in range(1000)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable(name:init_theta, observable:True, observed:False, tagged:False, control:True, address:20__forward__initialize_direction_isotropic__?__Uniform__1, distribution:Uniform(low=-1.0, high=1.0), value:tensor(0.9995), log_importance_weight:0.001259922981262207, log_prob:tensor(-0.6931)),\n",
       " Variable(name:init_phi, observable:True, observed:False, tagged:False, control:True, address:48__forward__initialize_direction_isotropic__phi__Uniform__1, distribution:Uniform(low=0.0, high=6.2831854820251465), value:tensor(0.4760), log_importance_weight:0.0015921592712402344, log_prob:tensor(-1.8379)),\n",
       " Variable(name:step_len_eta, observable:True, observed:False, tagged:False, control:True, address:96__forward__loop__step__eta__Uniform__1, distribution:Uniform(low=0.0, high=1.0), value:tensor(0.3114), log_importance_weight:-0.0006515979766845703, log_prob:tensor(0.)),\n",
       " Variable(name:obs0, observable:True, observed:True, tagged:False, control:False, address:94__forward__?__Categorical(len_probs:2)__1, distribution:Categorical(probs=[0.0, 1.0]), value:1, log_importance_weight:-1.1920930376163597e-07, log_prob:tensor(-1.1921e-07))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_samples[15].variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empirical(items:2000, weighted:True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
